ğŸ—ï¸ AI-Engine Architecture
Tá»•ng quan há»‡ thá»‘ng
AI-Engine lÃ  má»™t há»‡ thá»‘ng AI Ä‘a mÃ´-Ä‘un cho robot thÃ´ng minh, Ä‘Æ°á»£c thiáº¿t káº¿ theo kiáº¿n trÃºc module hÃ³a vÃ  cÃ³ kháº£ nÄƒng má»Ÿ rá»™ng cao.

ğŸ“ Kiáº¿n trÃºc tá»•ng thá»ƒ
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI-Engine Core                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Vision  â”‚  â”‚  Audio   â”‚  â”‚   NLP    â”‚            â”‚
â”‚  â”‚  Module  â”‚  â”‚  Module  â”‚  â”‚  Module  â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜            â”‚
â”‚       â”‚             â”‚              â”‚                   â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                     â”‚                                   â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚            â”‚    Behavior     â”‚                         â”‚
â”‚            â”‚     Engine      â”‚                         â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                     â”‚                                   â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚            â”‚    Analytics    â”‚                         â”‚
â”‚            â”‚     Module      â”‚                         â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  WebSocket Layer                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    REST API Layer                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   ESP32/Pi Robot     â”‚
              â”‚   Hardware           â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸ§© CÃ¡c Module chÃ­nh
1. Vision Module (src/core/vision/)
Chá»©c nÄƒng: Xá»­ lÃ½ hÃ¬nh áº£nh vÃ  video

Camera Manager: Quáº£n lÃ½ camera, capture frames
Face Detector: PhÃ¡t hiá»‡n khuÃ´n máº·t (Haar Cascade, DNN)
Face Recognizer: Nháº­n diá»‡n khuÃ´n máº·t (LBPH)
Motion Detector: PhÃ¡t hiá»‡n chuyá»ƒn Ä‘á»™ng (Background Subtraction)
Object Detector: PhÃ¡t hiá»‡n váº­t thá»ƒ (YOLO)
Pose Estimator: Æ¯á»›c lÆ°á»£ng tÆ° tháº¿ (MediaPipe)
Technology Stack:

OpenCV
YOLO (Ultralytics)
MediaPipe
NumPy
2. Audio Module (src/core/audio/)
Chá»©c nÄƒng: Xá»­ lÃ½ Ã¢m thanh vÃ  giá»ng nÃ³i

Audio Capture: Thu Ã¢m tá»« microphone
Speech-to-Text: Chuyá»ƒn giá»ng nÃ³i thÃ nh text (Whisper)
Text-to-Speech: Chuyá»ƒn text thÃ nh giá»ng nÃ³i (gTTS)
Voice Recognition: Nháº­n diá»‡n ngÆ°á»i nÃ³i (MFCC)
Sound Classifier: PhÃ¢n loáº¡i Ã¢m thanh
Noise Reducer: Giáº£m nhiá»…u audio
Technology Stack:

OpenAI Whisper
gTTS
Librosa
SoundDevice
3. NLP Module (src/core/nlp/)
Chá»©c nÄƒng: Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn

LLM Manager: Quáº£n lÃ½ LLMs (OpenAI, Claude, Ollama)
Conversation Engine: Quáº£n lÃ½ há»™i thoáº¡i
Intent Classifier: PhÃ¢n loáº¡i Ã½ Ä‘á»‹nh (Rule-based)
Entity Extractor: TrÃ­ch xuáº¥t thá»±c thá»ƒ (Regex)
Sentiment Analyzer: PhÃ¢n tÃ­ch cáº£m xÃºc (Lexicon-based)
Technology Stack:

OpenAI API
Anthropic Claude
Ollama (Local LLMs)
4. Behavior Module (src/core/behavior/)
Chá»©c nÄƒng: Quáº£n lÃ½ hÃ nh vi vÃ  cáº£m xÃºc

Behavior Engine: State machine cho behavior
Emotion Model: MÃ´ hÃ¬nh cáº£m xÃºc (Circumplex Model)
Decision Maker: Ra quyáº¿t Ä‘á»‹nh hÃ nh Ä‘á»™ng
Personality: TÃ­nh cÃ¡ch robot (Big Five)
Design Pattern:

State Machine Pattern
Observer Pattern
Strategy Pattern
5. Analytics Module (src/core/analytics/)
Chá»©c nÄƒng: PhÃ¢n tÃ­ch dá»¯ liá»‡u vÃ  dá»± Ä‘oÃ¡n

Sensor Analyzer: PhÃ¢n tÃ­ch dá»¯ liá»‡u sensor
Anomaly Detector: PhÃ¡t hiá»‡n báº¥t thÆ°á»ng (Z-score, IQR, MA)
Pattern Recognizer: Nháº­n diá»‡n patterns (Trend, Periodic, Spike)
Predictor: Dá»± Ä‘oÃ¡n tÆ°Æ¡ng lai (MA, ES, Linear, Ensemble)
Algorithms:

Statistical Methods
Time-Series Analysis
Linear Regression
6. WebSocket Service (src/services/websocket/)
Chá»©c nÄƒng: Real-time communication

WebSocket Client: Client vá»›i auto-reconnect
Message Handler: Routing messages
Protocols: Message schemas (Pydantic)
Features:

Auto-reconnection
Priority queue
Type-safe messages
Heartbeat mechanism
7. API Layer (src/api/)
Chá»©c nÄƒng: REST API endpoints

FastAPI framework
Pydantic schemas
CORS support
WebSocket endpoint
Health checks
Metrics (Prometheus)
ğŸ”„ Data Flow
User Input Flow
User Speech/Text
    â†“
Audio Capture / Text Input
    â†“
Speech-to-Text (if audio)
    â†“
NLP Processing
    â”œâ”€â†’ Intent Classification
    â”œâ”€â†’ Entity Extraction
    â””â”€â†’ Sentiment Analysis
    â†“
Behavior Engine
    â”œâ”€â†’ Update Emotion
    â”œâ”€â†’ Change State
    â””â”€â†’ Decision Making
    â†“
Action Execution
    â”œâ”€â†’ TTS Response
    â”œâ”€â†’ Device Control
    â””â”€â†’ Movement
Vision Processing Flow
Camera Frame
    â†“
Frame Buffer
    â†“
Vision Processing (parallel)
    â”œâ”€â†’ Face Detection
    â”œâ”€â†’ Motion Detection
    â”œâ”€â†’ Object Detection
    â””â”€â†’ Pose Estimation
    â†“
Results â†’ Behavior Engine
    â†“
Decision & Action
ğŸ—„ï¸ Data Storage
In-Memory
Conversation history (deque, max 50)
Sensor buffers (deque, max 1000)
Frame buffers (ring buffer)
Audio buffers (ring buffer)
Persistent Storage
Face embeddings (pickle)
Voice prints (pickle)
Configuration (yaml, env)
Logs (file rotation)
Cache (Redis)
Session data
Temporary results
Rate limiting
ğŸ” Security
API Security
API Key authentication (optional)
CORS configuration
Input validation (Pydantic)
Rate limiting
Data Security
Sensitive data in .env
No hardcoded credentials
Secure WebSocket (WSS)
âš¡ Performance
Optimization Strategies
Async/Await: Non-blocking I/O
Threading: CPU-bound tasks
Buffer Management: Ring buffers
Lazy Loading: Models on-demand
Caching: Redis for frequent data
Resource Management
Memory Limits: Configurable buffers
GPU Support: CUDA for inference
FPS Control: Adjustable processing rate
ğŸ”Œ Integration Points
Hardware Integration
ESP32/Raspberry Pi
    â†“ (WebSocket)
AI-Engine
    â†“ (Commands)
ESP32/Raspberry Pi
    â†“ (GPIO/I2C)
Actuators/Sensors
External Services
OpenAI API: GPT models
Anthropic API: Claude models
Ollama: Local LLMs
Redis: Caching
Prometheus: Metrics
Grafana: Visualization
ğŸ“¦ Deployment Architecture
Development
Local Machine
â”œâ”€â”€ AI-Engine (Python)
â”œâ”€â”€ Redis (Docker)
â””â”€â”€ Mock ESP32 (WebSocket Server)
Production
Docker Compose
â”œâ”€â”€ ai-engine (container)
â”œâ”€â”€ redis (container)
â”œâ”€â”€ prometheus (container)
â””â”€â”€ grafana (container)
    â†“ (network)
ESP32 Robot (physical)
Cloud Deployment (Optional)
Kubernetes Cluster
â”œâ”€â”€ AI-Engine Pods (replicas)
â”œâ”€â”€ Redis Cluster
â”œâ”€â”€ Load Balancer
â””â”€â”€ Monitoring Stack
ğŸ”§ Configuration Management
Hierarchy
Environment variables (.env)
Configuration files (config/)
Runtime settings (API)
Default values (code)
Settings Categories
System: ENV, DEBUG, LOG_LEVEL
WebSocket: URL, timeouts, retries
Camera: resolution, FPS, features
Audio: sample rate, models
LLM: provider, model, tokens
Behavior: personality, emotions
Performance: workers, memory, GPU
ğŸ§ª Testing Strategy
Unit Tests
Individual modules
Pure functions
Mock external dependencies
Integration Tests
Module interactions
WebSocket communication
API endpoints
End-to-End Tests
Complete workflows
Real hardware (optional)
Performance benchmarks
ğŸ“ˆ Scalability
Horizontal Scaling
Multiple AI-Engine instances
Load balancer
Shared Redis cache
Vertical Scaling
GPU acceleration
Multi-threading
Optimized models
ğŸ”® Future Enhancements
Planned Features
 Deep Learning models (TensorFlow, PyTorch)
 Advanced voice cloning
 3D object detection
 Reinforcement learning for behavior
 Multi-robot coordination
 Cloud integration (AWS, Azure)
 Mobile app control
Architecture Improvements
 Microservices architecture
 Event-driven design
 GraphQL API
 WebRTC for video streaming
 Kubernetes deployment
